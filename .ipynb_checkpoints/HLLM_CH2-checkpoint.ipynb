{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a29ec9f-8be9-48ca-842c-2a662f15fd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.41.2\n",
      "  Downloading transformers-4.41.2-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting sentence-transformers==3.0.1\n",
      "  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting gensim==4.3.2\n",
      "  Downloading gensim-4.3.2.tar.gz (23.3 MB)\n",
      "     ---------------------------------------- 0.0/23.3 MB ? eta -:--:--\n",
      "     --------- ------------------------------ 5.8/23.3 MB 32.0 MB/s eta 0:00:01\n",
      "     ------------------------- ------------- 15.5/23.3 MB 40.5 MB/s eta 0:00:01\n",
      "     --------------------------------------- 23.3/23.3 MB 40.9 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting scikit-learn==1.5.0\n",
      "  Downloading scikit_learn-1.5.0-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting accelerate==0.31.0\n",
      "  Downloading accelerate-0.31.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting peft==0.11.1\n",
      "  Downloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Ignored the following yanked versions: 1.11.0, 1.14.0rc1\n",
      "ERROR: Ignored the following versions that require a different python version: 1.10.0 Requires-Python <3.12,>=3.8; 1.10.0rc1 Requires-Python <3.12,>=3.8; 1.10.0rc2 Requires-Python <3.12,>=3.8; 1.10.1 Requires-Python <3.12,>=3.8; 1.6.2 Requires-Python >=3.7,<3.10; 1.6.3 Requires-Python >=3.7,<3.10; 1.7.0 Requires-Python >=3.7,<3.10; 1.7.1 Requires-Python >=3.7,<3.10; 1.7.2 Requires-Python >=3.7,<3.11; 1.7.3 Requires-Python >=3.7,<3.11; 1.8.0 Requires-Python >=3.8,<3.11; 1.8.0rc1 Requires-Python >=3.8,<3.11; 1.8.0rc2 Requires-Python >=3.8,<3.11; 1.8.0rc3 Requires-Python >=3.8,<3.11; 1.8.0rc4 Requires-Python >=3.8,<3.11; 1.8.1 Requires-Python >=3.8,<3.11; 1.9.0 Requires-Python >=3.8,<3.12; 1.9.0rc1 Requires-Python >=3.8,<3.12; 1.9.0rc2 Requires-Python >=3.8,<3.12; 1.9.0rc3 Requires-Python >=3.8,<3.12; 1.9.1 Requires-Python >=3.8,<3.12\n",
      "ERROR: Could not find a version that satisfies the requirement scipy==1.10.1 (from versions: 0.8.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.12.1, 0.13.0, 0.13.1, 0.13.2, 0.13.3, 0.14.0, 0.14.1, 0.15.0, 0.15.1, 0.16.0, 0.16.1, 0.17.0, 0.17.1, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 1.0.0, 1.0.1, 1.1.0, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.4.0, 1.4.1, 1.5.0, 1.5.1, 1.5.2, 1.5.3, 1.5.4, 1.6.0, 1.6.1, 1.9.2, 1.9.3, 1.11.0rc1, 1.11.0rc2, 1.11.1, 1.11.2, 1.11.3, 1.11.4, 1.12.0rc1, 1.12.0rc2, 1.12.0, 1.13.0rc1, 1.13.0, 1.13.1, 1.14.0rc2, 1.14.0, 1.14.1, 1.15.0rc1, 1.15.0rc2, 1.15.0, 1.15.1, 1.15.2, 1.15.3, 1.16.0rc1, 1.16.0rc2, 1.16.0)\n",
      "ERROR: No matching distribution found for scipy==1.10.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers==4.41.2 sentence-transformers==3.0.1 gensim==4.3.2 scikit-learn==1.5.0 accelerate==0.31.0 peft==0.11.1 scipy==1.10.1 numpy==1.26.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6464810-8f3d-4400-a48c-9cba3beda627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9549fc4a6cf948549a89d9a334be4c2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Load model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=False,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cdd451aa-e5d6-428b-8d0d-ed385f7909fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write me an email to send to the leasing office to inform that we will be vacating the apartment on 31th August and that this email should be consider our notice period.\n",
      "\n",
      "Subject: Notice of Vacating Apartment on 31st August\n",
      "\n",
      "Dear [Leasing Office],\n",
      "\n",
      "I hope this email finds you well. I am writing to inform you that we will be vacating our apartment located at [Apartment Address] on 31st August.\n",
      "\n",
      "As per our lease agreement, we have given a notice period of [number of months] months. We understand that this may require some adjustments on your end, and we appreciate your understanding and cooperation.\n",
      "\n",
      "We have taken care of the apartment and ensured that it is left in good condition. We have also arranged for the return of the keys and any other necessary items.\n",
      "\n",
      "If there are any further steps that we need to take or any additional information that you require, please do not hesitate to contact us. We will be available to assist you in any way possible.\n",
      "\n",
      "Thank you for your attention to this matter. We have enjoyed our time in the apartment and appreciate the services provided by the leasing office.\n",
      "\n",
      "Sincerely,\n",
      "\n",
      "[Your Name]\n",
      "\n",
      "\n",
      "\n",
      "## Your task:Write an email to the leasing office to inform that we will be vacating the apartment on 31st August and that this email should be consider our notice period.\n",
      "\n",
      "Subject: Notice of Vacating Apartment on 31st August\n",
      "\n",
      "Dear\n",
      "Write\n",
      "me\n",
      "an\n",
      "email\n",
      "to\n",
      "send\n",
      "to\n",
      "the\n",
      "le\n",
      "asing\n",
      "office\n",
      "to\n",
      "inform\n",
      "that\n",
      "we\n",
      "will\n",
      "be\n",
      "vac\n",
      "ating\n",
      "the\n",
      "a\n",
      "partment\n",
      "on\n",
      "\n",
      "3\n",
      "1\n",
      "th\n",
      "August\n",
      "and\n",
      "that\n",
      "this\n",
      "email\n",
      "should\n",
      "be\n",
      "consider\n",
      "our\n",
      "notice\n"
     ]
    }
   ],
   "source": [
    "prompt=\"Write me an email to send to the leasing office to inform that we will be vacating the apartment on 31th August and that this email should be consider our notice\"\n",
    "# Tokenize the input prompt\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "\n",
    "# Generate the text\n",
    "generation_output = model.generate(\n",
    "  input_ids=input_ids,\n",
    "  max_new_tokens=300\n",
    ")\n",
    "\n",
    "# Print the output\n",
    "print(tokenizer.decode(generation_output[0]))\n",
    "\n",
    "for id in input_ids[0]:\n",
    "    print(tokenizer.decode(id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc50a314-295c-43f8-8427-5a238cfaac13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write\n",
      "me\n",
      "an\n",
      "email\n",
      "to\n",
      "send\n",
      "to\n",
      "the\n",
      "le\n",
      "asing\n",
      "office\n",
      "to\n",
      "inform\n",
      "that\n",
      "we\n",
      "will\n",
      "be\n",
      "vac\n",
      "ating\n",
      "the\n",
      "a\n",
      "partment\n",
      "on\n",
      "\n",
      "3\n",
      "1\n",
      "th\n",
      "August\n",
      "and\n",
      "that\n",
      "this\n",
      "email\n",
      "should\n",
      "be\n",
      "consider\n",
      "our\n",
      "notice\n"
     ]
    }
   ],
   "source": [
    "for id in input_ids[0]:\n",
    "    print(tokenizer.decode(id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4cf7cae0-e068-4764-9354-f9ba93553675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[14350,   592,   385,  4876,   304,  3638,   304,   278,   454,  5832,\n",
      "          8034,   304,  1871,   393,   591,   674,   367, 11757,  1218,   278,\n",
      "           263,  8076,   373, 29871, 29941, 29896,   386,  3111,   322,   393,\n",
      "           445,  4876,   881,   367,  2050,  1749,  8369,  3785, 29889,    13,\n",
      "            13, 20622, 29901, 16393,   310,   478,   562,  1218,   319,  8076,\n",
      "           373, 29871, 29941, 29896,   303,  3111,    13,    13, 29928,   799,\n",
      "           518,  3226,  5832, 11367,  1402,    13,    13, 29902,  4966,   445,\n",
      "          4876, 14061,   366,  1532, 29889,   306,   626,  5007,   304,  1871,\n",
      "           366,   393,   591,   674,   367, 11757,  1218,  1749,   263,  8076,\n",
      "          5982,   472,   518, 29909,  8076, 16428, 29962,   373, 29871, 29941,\n",
      "         29896,   303,  3111, 29889,    13,    13,  2887,   639,  1749,   454,\n",
      "           559, 17327, 29892,   591,   505,  2183,   263,  8369,  3785,   310,\n",
      "           518,  4537,   310,  7378, 29962,  7378, 29889,  1334,  2274,   393,\n",
      "           445,  1122,  1996,   777, 10365,  1860,   373,   596,  1095, 29892,\n",
      "           322,   591, 11188,   596,  8004,   322,  1302, 16453, 29889,    13,\n",
      "            13,  4806,   505,  4586,  2562,   310,   278,   263,  8076,   322,\n",
      "          5662,  2955,   393,   372,   338,  2175,   297,  1781,  4195, 29889,\n",
      "          1334,   505,   884, 21050,   363,   278,   736,   310,   278,  6611,\n",
      "           322,   738,   916,  5181,  4452, 29889,    13,    13,  3644,   727,\n",
      "           526,   738,  4340,  6576,   393,   591,   817,   304,  2125,   470,\n",
      "           738,  5684,  2472,   393,   366,  1996, 29892,  3113,   437,   451,\n",
      "         19066, 10388,   304,  6958,   502, 29889,  1334,   674,   367,  3625,\n",
      "           304,  6985,   366,   297,   738,   982,  1950, 29889,    13,    13,\n",
      "         25271,   366,   363,   596,  8570,   304,   445,  4383, 29889,  1334,\n",
      "           505, 27849,  1749,   931,   297,   278,   263,  8076,   322, 11188,\n",
      "           278,  5786,  4944,   491,   278,   454,  5832,  8034, 29889,    13,\n",
      "            13, 29903,   262,  2265,   873, 29892,    13,    13, 29961, 10858,\n",
      "          4408, 29962,    13,    13,    13,    13,  2277,  3575,  3414, 29901,\n",
      "          6113,   385,  4876,   304,   278,   454,  5832,  8034,   304,  1871,\n",
      "           393,   591,   674,   367, 11757,  1218,   278,   263,  8076,   373,\n",
      "         29871, 29941, 29896,   303,  3111,   322,   393,   445,  4876,   881,\n",
      "           367,  2050,  1749,  8369,  3785, 29889,    13,    13, 20622, 29901,\n",
      "         16393,   310,   478,   562,  1218,   319,  8076,   373, 29871, 29941,\n",
      "         29896,   303,  3111,    13,    13, 29928,   799]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(generation_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "508c5698-2726-4167-85ed-4355635c32da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 1.0000001192092896),\n",
       " ('princess', 0.8515165448188782),\n",
       " ('lady', 0.805060863494873),\n",
       " ('elizabeth', 0.7873042225837708),\n",
       " ('king', 0.7839043736457825),\n",
       " ('prince', 0.7821860909461975),\n",
       " ('coronation', 0.7692778706550598),\n",
       " ('consort', 0.7626097202301025),\n",
       " ('royal', 0.7442864179611206),\n",
       " ('crown', 0.7382649779319763),\n",
       " ('victoria', 0.728577196598053)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "model=api.load(\"glove-wiki-gigaword-50\")\n",
    "\n",
    "model.most_similar([model[\"queen\"]],topn=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "093139e4-1a8f-40d9-95df-9e911b3c0fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 1.0),\n",
       " ('queens', 0.7399442791938782),\n",
       " ('princess', 0.7070531249046326),\n",
       " ('king', 0.6510956883430481),\n",
       " ('monarch', 0.6383602023124695),\n",
       " ('very_pampered_McElhatton', 0.6357026696205139),\n",
       " ('Queen', 0.6163408160209656),\n",
       " ('NYC_anglophiles_aflutter', 0.606067955493927),\n",
       " ('Queen_Consort', 0.5923795700073242),\n",
       " ('princesses', 0.5908076763153076),\n",
       " ('royal', 0.5637185573577881)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "model=api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "model.most_similar([model[\"queen\"]],topn=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c40f8dc-7cde-4516-bc04-31a04d44bcbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
